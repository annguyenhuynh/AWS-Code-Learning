{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Bucket details\n",
    "input_bucket = \"s3_bucket\"\n",
    "input_prefix = \"input_folder/\"\n",
    "output_bucket = \"s3_bucket\"\n",
    "output_prefix = \"output_folder/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten JSON without parent keys in the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(nested_json, separator='_'):\n",
    "    \"\"\"Recursively flatten nested JSON and store only the innermost keys.\"\"\"\n",
    "    flattened = {}\n",
    "    for key, value in nested_json.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Recursively flatten the dictionary\n",
    "            flattened.update(flatten_json(value, separator))  # Don't include parent key in recursion\n",
    "        elif isinstance(value, list):\n",
    "            # If a list contains dictionaries, handle them separately\n",
    "            if all(isinstance(item, dict) for item in value):\n",
    "                # For each dictionary in the list, flatten individually\n",
    "                for i, item in enumerate(value):\n",
    "                    flattened.update(flatten_json(item, separator))\n",
    "            else:\n",
    "                # If the list contains non-dictionaries, store them as a JSON string\n",
    "                flattened[key] = json.dumps(value)\n",
    "        else:\n",
    "            # If it's a leaf value, add it to the flattened structure\n",
    "            flattened[key] = value\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explain\n",
    "\n",
    "* This function flatten_json takes a nested JSON object and flattens it by extracting only the innermost keys while discarding the hierarchy.\n",
    "\n",
    "- **Initial Setup:**\n",
    "* 1. It initializes an empty dictionary flattened to store the flattened key-value pairs.\n",
    "* 2. It iterates through the key-value pairs of the given JSON.\n",
    "\n",
    "- **Handling Nested Dictionaries:**\n",
    "* 1. If a value is a dictionary (dict), the function calls itself recursively to flatten it further.\n",
    "* 2. It does not include the parent key in recursion, meaning that hierarchical keys (e.g., \"parent.child\" ) will not be preserved.\n",
    "\n",
    "- **Handling Lists (list):**\n",
    "* 1. If the list contains only dictionaries, each dictionary in the list is flattened separately.\n",
    "* 2. If the list contains primitive values (strings, numbers, etc.), it is stored as a JSON string to keep the structure.\n",
    "\n",
    "- **Handling Leaf Nodes:**\n",
    "* 1. If a value is neither a dictionary nor a list (i.e., a primitive value), it is directly added to the flattened dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_csv(file_key):\n",
    "    # Get the JSON content from S3\n",
    "    response = s3_client.get_object(Bucket=input_bucket, Key=file_key)\n",
    "    json_data = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "    # Flatten the JSON structure\n",
    "    flattened_data = flatten_json(json_data)\n",
    "\n",
    "    # Convert JSON to DataFrame\n",
    "    df = pd.DataFrame([flattened_data])\n",
    "\n",
    "    # Save the CSV content to a StringIO buffer\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    # Define output file key (replace .json with .csv)\n",
    "    output_file_key = f\"{output_prefix}{file_key.split('/')[-1].replace('.json', '.csv')}\"\n",
    "\n",
    "    # Upload the CSV to S3\n",
    "    s3_client.put_object(Bucket=output_bucket, Key=output_file_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "    print(f\"Converted and uploaded: {output_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List JSON files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_json_files():\n",
    "    files = []\n",
    "    response = s3_client.list_objects_v2(Bucket=input_bucket, Prefix=input_prefix)\n",
    "    while \"Contents\" in response:\n",
    "        for obj in response[\"Contents\"]:\n",
    "            if obj[\"Key\"].endswith(\".json\"):\n",
    "                files.append(obj[\"Key\"])\n",
    "        if response.get(\"IsTruncated\"):\n",
    "            response = s3_client.list_objects_v2(\n",
    "                Bucket=input_bucket, Prefix=input_prefix,\n",
    "                ContinuationToken=response[\"NextContinuationToken\"]\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process all JSON files\n",
    "def main():\n",
    "    json_files = list_json_files()\n",
    "    for file_key in json_files:\n",
    "        json_to_csv(file_key)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
